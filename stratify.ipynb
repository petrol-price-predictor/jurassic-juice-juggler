{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pyarrow\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import deque\n",
    "from src.config.paths import ROOT_DIR, SAMPLE_DIR, PRICES_DIR, META_DIR\n",
    "\n",
    "import src.fileutils as files\n",
    "import src.visualization as viz\n",
    "import src.process as process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_info_file = ROOT_DIR / 'data' / 'stations.csv'\n",
    "sample_file_location = SAMPLE_DIR\n",
    "sample_price_location = SAMPLE_DIR / 'prices'\n",
    "\n",
    "RSEED = 42\n",
    "random.seed(RSEED)\n",
    "np.random.seed(RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014\\10\\2014-10-26-prices.csv\n",
    "# 2015\\03\\2015-03-29-prices.csv\n",
    "# 2016\\05\\2016-05-01-prices.csv\n",
    "# 2018\\03\\2018-03-25-prices.csv\n",
    "# 2018\\10\\2018-10-28-prices.csv\n",
    "# 2020\\03\\2020-03-29-prices.csv\n",
    "# 2020\\10\\2020-10-25-prices.csv\n",
    "# 2021\\03\\2021-03-28-prices.csv\n",
    "# 2021\\10\\2021-10-31-prices.csv\n",
    "# 2022\\03\\2022-03-27-prices.csv\n",
    "# 2022\\10\\2022-10-30-prices.csv\n",
    "# 2023\\03\\2023-03-26-prices.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closing_prices(prices_df):\n",
    "\n",
    "    return prices_df.groupby(level='station').tail(1)\n",
    "\n",
    "\n",
    "def impute_closing_prices(new_prices, closing_prices):\n",
    "\n",
    "    opening_prices = new_prices.groupby(level='station').head(1).reset_index(level=1)\n",
    "    opening_prices = opening_prices.fillna(closing_prices.reset_index(level=1))\n",
    "\n",
    "    # set the datetime index back to where it was and update the new prices with the opening prices\n",
    "    opening_prices = opening_prices.set_index('date', append=True)\n",
    "    new_prices.update(opening_prices, overwrite = False)\n",
    "    return new_prices\n",
    "\n",
    "\n",
    "def fill_missing_prices(prices_df, method='ffill'):\n",
    "    prices_df[['diesel', 'e5', 'e10']] = prices_df \\\n",
    "        .groupby(level='station')[['diesel', 'e5', 'e10']] \\\n",
    "        .fillna(method=method)\n",
    "    \n",
    "    return prices_df\n",
    "\n",
    "####################################\n",
    "\n",
    "# INSTANTIATE EVERYTHING OF THIS\n",
    "prices_meta = pd.DataFrame()\n",
    "closing_prices = pd.DataFrame()\n",
    "last_closing_prices = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Read Data\n",
    "prices_df_raw = pd.read_csv(PRICES_DIR / '2020' / '03' / '2020-03-29-prices.csv')\n",
    "prices_df_raw2 = pd.read_csv(PRICES_DIR / '2020' / '03' / '2020-03-30-prices.csv')\n",
    "dus_stations = pd.read_csv(SAMPLE_DIR / 'stations' / 'stations_dus_plus.csv')\n",
    "\n",
    "# Create a set of all UUIDs in the DUS subsample\n",
    "dus_station_uuid = set(dus_stations.uuid)\n",
    "\n",
    "####################################\n",
    "# PROCESS DAY 1\n",
    "\n",
    "# Drop the 'change' columns for now as they dont provide us with any insight. FUTURE FEATURE ENGINEERING\n",
    "# First Processing Step for Day 1: Drop all but DUS, generate panel\n",
    "prices_df = prices_df_raw.drop(columns=prices_df_raw.filter(like='change').columns)\n",
    "prices_df = prices_df[prices_df.station_uuid.isin(dus_station_uuid)]\n",
    "\n",
    "df = process.extend_panel(prices_df)\n",
    "df = process.swap_sort_index(df)\n",
    "\n",
    "if not last_closing_prices.empty:\n",
    "        df = impute_closing_prices(df, last_closing_prices)\n",
    "df = fill_missing_prices(df)\n",
    "\n",
    "####################################\n",
    "# POSTPROCESS DAY 1: GENERATE METADATA FOR THAT DAY\n",
    "\n",
    "last_closing_prices = get_closing_prices(df)\n",
    "# closing_prices.append_last_closing_prices()\n",
    "\n",
    "####################################\n",
    "# PROCESS DAY 2\n",
    "\n",
    "# First Processing Step for Day 2: Drop all but DUS, generate panel\n",
    "prices_df2 = prices_df_raw2.drop(columns=prices_df_raw2.filter(like='change').columns)\n",
    "prices_df2 = prices_df2[prices_df2.station_uuid.isin(dus_station_uuid)]\n",
    "\n",
    "df2 = process.extend_panel(prices_df2)\n",
    "df2 = process.swap_sort_index(df2)\n",
    "\n",
    "if not last_closing_prices.empty:\n",
    "        df2 = impute_closing_prices(df2, last_closing_prices)\n",
    "df2 = fill_missing_prices(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features:\n",
    "# relative prices\n",
    "# opening hours + dummies\n",
    "# holiday dummies\n",
    "# school-holyday dummies\n",
    "# crude oil\n",
    "# with bins: change count/hour\n",
    "\n",
    "# Meta\n",
    "# Average Price per day (per product)\n",
    "# Trade Frequency\n",
    "# was this a holiday\n",
    "# was this a schoolholiday\n",
    "# year\n",
    "# month\n",
    "# day\n",
    "# weekday\n",
    "# average crude oil price that day\n",
    "\n",
    "# Processing\n",
    "# bin dates\n",
    "# Split into 3 prices (more data but faster processing maybe?)\n",
    "# make additional features independent  at first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>diesel</th>\n",
       "      <th>e5</th>\n",
       "      <th>e10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>005056ba-7cb6-1ed2-bceb-7e82e4910d2a</th>\n",
       "      <th>2020-03-29 23:59:08+02:00</th>\n",
       "      <td>1.079</td>\n",
       "      <td>1.209</td>\n",
       "      <td>1.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005056ba-7cb6-1ed2-bceb-7ef561844d2a</th>\n",
       "      <th>2020-03-29 23:59:08+02:00</th>\n",
       "      <td>1.079</td>\n",
       "      <td>1.219</td>\n",
       "      <td>1.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005056ba-7cb6-1ed2-bceb-80c585ca6d2b</th>\n",
       "      <th>2020-03-29 23:59:08+02:00</th>\n",
       "      <td>1.079</td>\n",
       "      <td>1.209</td>\n",
       "      <td>1.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005056ba-7cb6-1ed2-bceb-82ea369c0d2d</th>\n",
       "      <th>2020-03-29 23:59:08+02:00</th>\n",
       "      <td>1.079</td>\n",
       "      <td>1.219</td>\n",
       "      <td>1.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005056ba-7cb6-1ed2-bceb-87f71ccd4d30</th>\n",
       "      <th>2020-03-29 23:59:08+02:00</th>\n",
       "      <td>1.079</td>\n",
       "      <td>1.219</td>\n",
       "      <td>1.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa6624d4-7bb9-4b17-9e56-31e0040428d1</th>\n",
       "      <th>2020-03-29 23:59:08+02:00</th>\n",
       "      <td>1.159</td>\n",
       "      <td>1.279</td>\n",
       "      <td>1.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbcdf8a7-b6ba-4ec3-ac4c-dde2f0f29934</th>\n",
       "      <th>2020-03-29 23:59:08+02:00</th>\n",
       "      <td>1.079</td>\n",
       "      <td>1.209</td>\n",
       "      <td>1.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fcdaddc5-7dc1-49f9-8286-71e8664f9e17</th>\n",
       "      <th>2020-03-29 23:59:08+02:00</th>\n",
       "      <td>1.039</td>\n",
       "      <td>1.199</td>\n",
       "      <td>1.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd99c048-3b6b-4943-8b93-838daefba76b</th>\n",
       "      <th>2020-03-29 23:59:08+02:00</th>\n",
       "      <td>1.139</td>\n",
       "      <td>1.269</td>\n",
       "      <td>1.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff55d404-3609-48b2-b16a-ef4a9f2008a0</th>\n",
       "      <th>2020-03-29 23:59:08+02:00</th>\n",
       "      <td>1.049</td>\n",
       "      <td>1.179</td>\n",
       "      <td>1.149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2332 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                diesel     e5   \n",
       "station                              date                                       \n",
       "005056ba-7cb6-1ed2-bceb-7e82e4910d2a 2020-03-29 23:59:08+02:00   1.079  1.209  \\\n",
       "005056ba-7cb6-1ed2-bceb-7ef561844d2a 2020-03-29 23:59:08+02:00   1.079  1.219   \n",
       "005056ba-7cb6-1ed2-bceb-80c585ca6d2b 2020-03-29 23:59:08+02:00   1.079  1.209   \n",
       "005056ba-7cb6-1ed2-bceb-82ea369c0d2d 2020-03-29 23:59:08+02:00   1.079  1.219   \n",
       "005056ba-7cb6-1ed2-bceb-87f71ccd4d30 2020-03-29 23:59:08+02:00   1.079  1.219   \n",
       "...                                                                ...    ...   \n",
       "fa6624d4-7bb9-4b17-9e56-31e0040428d1 2020-03-29 23:59:08+02:00   1.159  1.279   \n",
       "fbcdf8a7-b6ba-4ec3-ac4c-dde2f0f29934 2020-03-29 23:59:08+02:00   1.079  1.209   \n",
       "fcdaddc5-7dc1-49f9-8286-71e8664f9e17 2020-03-29 23:59:08+02:00   1.039  1.199   \n",
       "fd99c048-3b6b-4943-8b93-838daefba76b 2020-03-29 23:59:08+02:00   1.139  1.269   \n",
       "ff55d404-3609-48b2-b16a-ef4a9f2008a0 2020-03-29 23:59:08+02:00   1.049  1.179   \n",
       "\n",
       "                                                                  e10  \n",
       "station                              date                              \n",
       "005056ba-7cb6-1ed2-bceb-7e82e4910d2a 2020-03-29 23:59:08+02:00  1.179  \n",
       "005056ba-7cb6-1ed2-bceb-7ef561844d2a 2020-03-29 23:59:08+02:00  1.189  \n",
       "005056ba-7cb6-1ed2-bceb-80c585ca6d2b 2020-03-29 23:59:08+02:00  1.179  \n",
       "005056ba-7cb6-1ed2-bceb-82ea369c0d2d 2020-03-29 23:59:08+02:00  1.189  \n",
       "005056ba-7cb6-1ed2-bceb-87f71ccd4d30 2020-03-29 23:59:08+02:00  1.189  \n",
       "...                                                               ...  \n",
       "fa6624d4-7bb9-4b17-9e56-31e0040428d1 2020-03-29 23:59:08+02:00  1.249  \n",
       "fbcdf8a7-b6ba-4ec3-ac4c-dde2f0f29934 2020-03-29 23:59:08+02:00  1.179  \n",
       "fcdaddc5-7dc1-49f9-8286-71e8664f9e17 2020-03-29 23:59:08+02:00  1.169  \n",
       "fd99c048-3b6b-4943-8b93-838daefba76b 2020-03-29 23:59:08+02:00  1.239  \n",
       "ff55d404-3609-48b2-b16a-ef4a9f2008a0 2020-03-29 23:59:08+02:00  1.149  \n",
       "\n",
       "[2332 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "datetime.date(2020, 3, 29)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#closing_prices = pd.DataFrame()\n",
    "closing_prices = pd.concat([closing_prices, last_closing_prices], axis=0)\n",
    "display(closing_prices)\n",
    "closing_prices.tail(1).index.get_level_values(1)[0].date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\repos\\jurassic-juice-juggler\\data_processed\\stations\\prices_metadata_meta.csv\n",
      "D:\\repos\\jurassic-juice-juggler\\data_processed\\stations\\closing_prices_meta.csv\n"
     ]
    }
   ],
   "source": [
    "meta_dir = META_DIR\n",
    "suffix = 'meta'\n",
    "\n",
    "metadata = {\n",
    "            'prices_metadata': closing_prices,\n",
    "            'closing_prices' : df,\n",
    "        }\n",
    "\n",
    "\n",
    "if suffix:\n",
    "    suffix = f\"_{suffix}\"\n",
    "else:\n",
    "    suffix = ''\n",
    "\n",
    "for file_name, data in metadata.items():\n",
    "    file_path = Path(meta_dir / f'{file_name}{suffix}.csv')\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'closing_price' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m             df\u001b[39m.\u001b[39mto_csv(file_path, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     33\u001b[0m closing_prices_path \u001b[39m=\u001b[39m META_DIR \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mclosing_prices.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 34\u001b[0m save_closing_prices(closing_price, closing_prices_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'closing_price' is not defined"
     ]
    }
   ],
   "source": [
    "# ADD PRICE CHANGES PER DAY FOR EACH STATION TO THE CLOSING TABLE\n",
    "# CONVERT DATE TO ONLY DAY-DATE\n",
    "# APPEND TO THE EXISTING 'CLOSING_PRICES.CSV'\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "def save_closing_prices(df, file_path, date='date'):\n",
    "    file_path = Path(file_path)\n",
    "    \n",
    "    # If the file doesn't exist, write the DataFrame to a new CSV file\n",
    "    if not file_path.is_file():        \n",
    "        df.to_csv(file_path, index=True)\n",
    "\n",
    "    # If it does exist, compare the last line of the CSV File with the last line of the DataFrame df\n",
    "    else:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            last_line = deque(file, 1)[0]\n",
    "\n",
    "        # Making sure the lines format is comparable \n",
    "        # CURRENTLY ONLY WORKS WITH DATE ON COLUMN INDEX 1\n",
    "        old_timestamp = pd.to_datetime(last_line.split(',')[1])\n",
    "        new_timestamp = pd.to_datetime(df[date].max())\n",
    "        \n",
    "        # If the new data is not already in the CSV File, append the DataFrame and safe the CSV file.\n",
    "        if new_timestamp <= old_timestamp:\n",
    "            print(\"Some data already exists in the CSV file. Data was not appended.\")\n",
    "        else:\n",
    "            df.to_csv(file_path, mode='a', header=False, index=True)\n",
    "\n",
    "\n",
    "closing_prices_path = META_DIR / 'closing_prices.csv'\n",
    "save_closing_prices(closing_price, closing_prices_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_table(df):\n",
    "    # if csv exists, just open that\n",
    "    # if not create a new pd.DataFrame\n",
    "    # add #observations\n",
    "    # add \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A METATABLE WITH DAILY SUMMARY:\n",
    "# - ACTIVE STATIONS\n",
    "# - NUMBER OF TIMESTAMPS\n",
    "def add_to_meta_table():\n",
    "    # open closing table file\n",
    "    # append daily meta DataFrame\n",
    "    # save file\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_stations = prices_data09.station_uuid.unique()\n",
    "# active_stations_sample = np.random.choice(active_stations, size=100)\n",
    "# pds = prices_df.query('station_uuid in @active_stations_sample')\n",
    "# pds\n",
    "\n",
    "\n",
    "\n",
    "# create a table that carries all stations for each hour of the day\n",
    "\n",
    "# group by the hour of the day, take the average price if a station is occuring more than once during that time\n",
    "\n",
    "# if a station occurs, check the *change columns if its a 2 or a 3, and if yes, check if the price is actually different from the previous hour of if prices have just been re-reported\n",
    "\n",
    "# if prices changed then make a 1 in the price-changed-dummies\n",
    "\n",
    "# if there are multiple occurences of the same station within one hour, check which prices changed and make en entry for the respective dummy\n",
    "\n",
    "# if there are multiple occurences of the same station within one hour, for each of the 3 fuel prices, count how often it changed\n",
    "\n",
    "# take a batch for each hour of the day\n",
    "\n",
    "# check \n",
    "\n",
    "# df = pd.merge(df, pds, how='left', on=['date', 'station_uuid']).set_index(['date', 'station_uuid'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuel_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
