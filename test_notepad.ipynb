{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pyarrow\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import deque\n",
    "from src.config.paths import ROOT_DIR, SAMPLE_DIR, PRICES_DIR, META_DIR, PROCESSED_PRICES\n",
    "\n",
    "import src.fileutils as files\n",
    "import src.visualization as viz\n",
    "import src.process as process\n",
    "from src import process_prices\n",
    "\n",
    "from src.process_files import PriceProcessor, RawPriceProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_info_file = ROOT_DIR / 'data' / 'stations.csv'\n",
    "sample_file_location = SAMPLE_DIR\n",
    "sample_price_location = SAMPLE_DIR / 'prices'\n",
    "\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RSEED)\n",
    "import inspect\n",
    "\n",
    "dus_stations_data = pd.read_csv(SAMPLE_DIR / 'stations' / 'stations_dus_plus.csv')\n",
    "dus_stations = dus_stations_data.uuid\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame({\n",
    "    'datetime': [dt.datetime.now() - dt.timedelta(days=i) for i in range(10)],\n",
    "    'string': ['string' + str(i) for i in range(10)],\n",
    "    'integer': np.random.randint(0, 100, size=10),\n",
    "    'float1': np.random.rand(10),\n",
    "    'float2': np.random.rand(10),\n",
    "})\n",
    "\n",
    "\n",
    "# class return_one():\n",
    "#     def __init__(self, data: pd.DataFrame, method=None):\n",
    "#         self.one = 1\n",
    "#         self.data = data\n",
    "#         self.predefined_methods = {\n",
    "#             'hourly': process_prices.make_hourly\n",
    "#         }\n",
    "#         self.set_method(method)\n",
    "     \n",
    "#     def set_method(self, method,):\n",
    "\n",
    "#         if method is None:\n",
    "#             self.method = None\n",
    "\n",
    "#         elif type(method) == str:\n",
    "#             if method not in self.predefined_methods:\n",
    "#                 raise ValueError(f\"{method} is not a a predefined method.\")\n",
    "#             self.method = self.predefined_methods[method]\n",
    "        \n",
    "#         elif inspect.isfunction(method):\n",
    "#             params = inspect.signature(method).parameters.values()\n",
    "#             if len(params) != 1:\n",
    "#                 raise ValueError(f\"{method} is required to take only 1 parameter but {len(params)} were given.\")\n",
    "#             self.method = method\n",
    "\n",
    "#         else:\n",
    "#             raise ValueError(\"Passed object is not a function or a predefined method\")\n",
    "    \n",
    "#     def process_data(self, data: pd.DataFrame, method=None, **kwargs) -> pd.DataFrame:\n",
    "\n",
    "#         if method:\n",
    "#             self.set_method(method, **kwargs)\n",
    "#         if self.method:\n",
    "#             data = self.method(data, **kwargs)\n",
    "\n",
    "#         else:\n",
    "#             raise ValueError(\"The method process_data requires a method to be set, but None was given.\")\n",
    "#         return data\n",
    "    \n",
    "def some_function(data: pd.DataFrame)->pd.DataFrame:\n",
    "\n",
    "    data = data.assign(\n",
    "        float1 = lambda x: x['float1']*10\n",
    "    )\n",
    "    return data\n",
    "\n",
    "def some_other_function(data: pd.DataFrame, multiplier = 10, add = 3)->pd.DataFrame:\n",
    "    data = data.assign(\n",
    "        float1 = lambda x: x['float1'] * multiplier + add\n",
    "    )\n",
    "    return data\n",
    "\n",
    "subset = {\n",
    "    'subset':dus_stations_data.uuid,\n",
    "    'subset_column': 'station_uuid',\n",
    "\n",
    "}\n",
    "dus_stations_data = pd.read_csv(SAMPLE_DIR / 'stations' / 'stations_dus_plus.csv')\n",
    "\n",
    "rawprocessor = RawPriceProcessor(PRICES_DIR, (PROCESSED_PRICES / 'test'), **subset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2021-08-29    101\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "date\n",
       "2021-08-30    106\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "date\n",
       "2021-08-31    105\n",
       "2021-08-30      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "one = 'data/prices/2021/08/2021-08-29-prices.csv'\n",
    "two = 'data/prices/2021/08/2021-08-30-prices.csv'\n",
    "three = 'data/prices/2021/08/2021-08-31-prices.csv'\n",
    "\n",
    "rawprocessor.process_file(one)\n",
    "display(rawprocessor.last_closing_prices.date.dt.date.value_counts())\n",
    "rawprocessor.process_file(two)\n",
    "display(rawprocessor.last_closing_prices.date.dt.date.value_counts())\n",
    "rawprocessor.process_file(three)\n",
    "display(rawprocessor.last_closing_prices.date.dt.date.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2021-08-31    105\n",
       "2021-08-30      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(rawprocessor.last_closing_prices.date.dt.date.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>diesel</th>\n",
       "      <th>e5</th>\n",
       "      <th>e10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00041414-208c-4444-8888-acdc00000414</th>\n",
       "      <td>2021-08-31 23:19:08+02:00</td>\n",
       "      <td>1.379</td>\n",
       "      <td>1.579</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005056ba-7cb6-1ed2-bceb-7e82e4910d2a</th>\n",
       "      <td>2021-08-31 23:19:08+02:00</td>\n",
       "      <td>1.349</td>\n",
       "      <td>1.579</td>\n",
       "      <td>1.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005056ba-7cb6-1ed2-bceb-7ef561844d2a</th>\n",
       "      <td>2021-08-31 23:19:08+02:00</td>\n",
       "      <td>1.369</td>\n",
       "      <td>1.609</td>\n",
       "      <td>1.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005056ba-7cb6-1ed2-bceb-80c585ca6d2b</th>\n",
       "      <td>2021-08-31 23:19:08+02:00</td>\n",
       "      <td>1.369</td>\n",
       "      <td>1.609</td>\n",
       "      <td>1.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005056ba-7cb6-1ed2-bceb-82ea369c0d2d</th>\n",
       "      <td>2021-08-31 23:19:08+02:00</td>\n",
       "      <td>1.369</td>\n",
       "      <td>1.609</td>\n",
       "      <td>1.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa6624d4-7bb9-4b17-9e56-31e0040428d1</th>\n",
       "      <td>2021-08-31 23:19:08+02:00</td>\n",
       "      <td>1.409</td>\n",
       "      <td>1.649</td>\n",
       "      <td>1.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbcdf8a7-b6ba-4ec3-ac4c-dde2f0f29934</th>\n",
       "      <td>2021-08-31 23:19:08+02:00</td>\n",
       "      <td>1.369</td>\n",
       "      <td>1.609</td>\n",
       "      <td>1.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fcdaddc5-7dc1-49f9-8286-71e8664f9e17</th>\n",
       "      <td>2021-08-31 23:19:08+02:00</td>\n",
       "      <td>1.329</td>\n",
       "      <td>1.559</td>\n",
       "      <td>1.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd99c048-3b6b-4943-8b93-838daefba76b</th>\n",
       "      <td>2021-08-31 23:19:08+02:00</td>\n",
       "      <td>1.419</td>\n",
       "      <td>1.669</td>\n",
       "      <td>1.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff55d404-3609-48b2-b16a-ef4a9f2008a0</th>\n",
       "      <td>2021-08-31 23:19:08+02:00</td>\n",
       "      <td>1.329</td>\n",
       "      <td>1.569</td>\n",
       "      <td>1.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          date  diesel     e5   \n",
       "station                                                                         \n",
       "00041414-208c-4444-8888-acdc00000414 2021-08-31 23:19:08+02:00   1.379  1.579  \\\n",
       "005056ba-7cb6-1ed2-bceb-7e82e4910d2a 2021-08-31 23:19:08+02:00   1.349  1.579   \n",
       "005056ba-7cb6-1ed2-bceb-7ef561844d2a 2021-08-31 23:19:08+02:00   1.369  1.609   \n",
       "005056ba-7cb6-1ed2-bceb-80c585ca6d2b 2021-08-31 23:19:08+02:00   1.369  1.609   \n",
       "005056ba-7cb6-1ed2-bceb-82ea369c0d2d 2021-08-31 23:19:08+02:00   1.369  1.609   \n",
       "...                                                        ...     ...    ...   \n",
       "fa6624d4-7bb9-4b17-9e56-31e0040428d1 2021-08-31 23:19:08+02:00   1.409  1.649   \n",
       "fbcdf8a7-b6ba-4ec3-ac4c-dde2f0f29934 2021-08-31 23:19:08+02:00   1.369  1.609   \n",
       "fcdaddc5-7dc1-49f9-8286-71e8664f9e17 2021-08-31 23:19:08+02:00   1.329  1.559   \n",
       "fd99c048-3b6b-4943-8b93-838daefba76b 2021-08-31 23:19:08+02:00   1.419  1.669   \n",
       "ff55d404-3609-48b2-b16a-ef4a9f2008a0 2021-08-31 23:19:08+02:00   1.329  1.569   \n",
       "\n",
       "                                        e10  \n",
       "station                                      \n",
       "00041414-208c-4444-8888-acdc00000414  0.000  \n",
       "005056ba-7cb6-1ed2-bceb-7e82e4910d2a  1.519  \n",
       "005056ba-7cb6-1ed2-bceb-7ef561844d2a  1.549  \n",
       "005056ba-7cb6-1ed2-bceb-80c585ca6d2b  1.549  \n",
       "005056ba-7cb6-1ed2-bceb-82ea369c0d2d  1.549  \n",
       "...                                     ...  \n",
       "fa6624d4-7bb9-4b17-9e56-31e0040428d1  1.589  \n",
       "fbcdf8a7-b6ba-4ec3-ac4c-dde2f0f29934  1.549  \n",
       "fcdaddc5-7dc1-49f9-8286-71e8664f9e17  1.499  \n",
       "fd99c048-3b6b-4943-8b93-838daefba76b  1.609  \n",
       "ff55d404-3609-48b2-b16a-ef4a9f2008a0  1.509  \n",
       "\n",
       "[105 rows x 4 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawprocessor.last_processed.groupby(level='station').tail(1).reset_index(level='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dus_stations_data = pd.read_csv(SAMPLE_DIR / 'stations' / 'stations_dus_plus.csv')\n",
    "dus_stations = dus_stations_data.uuid\n",
    "target_index = 'station'\n",
    "\n",
    "type(dus_stations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.paths import PRICES_DIR, PROCESSED_PRICES\n",
    "from src.config.paths import STATIONS_DIR, PROCESSED_STATIONS\n",
    "from src.config.paths import META_DIR, SAMPLE_DIR\n",
    "\n",
    "dus_stations_data = pd.read_csv(SAMPLE_DIR / 'stations' / 'stations_dus_plus.csv')\n",
    "dus_stations = dus_stations_data.uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_processed\\prices\\2021\\08\\2021-08-29-prices.csv\n",
    "# data_processed\\prices\\2021\\08\\2021-08-30-prices.csv\n",
    "# data_processed\\prices\\2021\\08\\2021-08-31-prices.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features:\n",
    "# relative prices\n",
    "# opening hours + dummies\n",
    "# holiday dummies\n",
    "# school-holyday dummies\n",
    "# crude oil\n",
    "# with bins: change count/hour\n",
    "\n",
    "# Meta\n",
    "# Average Price per day (per product)\n",
    "# Trade Frequency\n",
    "# was this a holiday\n",
    "# was this a schoolholiday\n",
    "# year\n",
    "# month\n",
    "# day\n",
    "# weekday\n",
    "# average crude oil price that day\n",
    "\n",
    "# Processing\n",
    "# bin dates\n",
    "# Split into 3 prices (more data but faster processing maybe?)\n",
    "# make additional features independent  at first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD PRICE CHANGES PER DAY FOR EACH STATION TO THE CLOSING TABLE\n",
    "# CONVERT DATE TO ONLY DAY-DATE\n",
    "# APPEND TO THE EXISTING 'CLOSING_PRICES.CSV'\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "def save_closing_prices(df, file_path, date='date'):\n",
    "    file_path = Path(file_path)\n",
    "    \n",
    "    # If the file doesn't exist, write the DataFrame to a new CSV file\n",
    "    if not file_path.is_file():        \n",
    "        df.to_csv(file_path, index=True)\n",
    "\n",
    "    # If it does exist, compare the last line of the CSV File with the last line of the DataFrame df\n",
    "    else:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            last_line = deque(file, 1)[0]\n",
    "\n",
    "        # Making sure the lines format is comparable \n",
    "        # CURRENTLY ONLY WORKS WITH DATE ON COLUMN INDEX 1\n",
    "        old_timestamp = pd.to_datetime(last_line.split(',')[1])\n",
    "        new_timestamp = pd.to_datetime(df[date].max())\n",
    "        \n",
    "        # If the new data is not already in the CSV File, append the DataFrame and safe the CSV file.\n",
    "        if new_timestamp <= old_timestamp:\n",
    "            print(\"Some data already exists in the CSV file. Data was not appended.\")\n",
    "        else:\n",
    "            df.to_csv(file_path, mode='a', header=False, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_table(df):\n",
    "    # if csv exists, just open that\n",
    "    # if not create a new pd.DataFrame\n",
    "    # add #observations\n",
    "    # add \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A METATABLE WITH DAILY SUMMARY:\n",
    "# - ACTIVE STATIONS\n",
    "# - NUMBER OF TIMESTAMPS\n",
    "def add_to_meta_table():\n",
    "    # open closing table file\n",
    "    # append daily meta DataFrame\n",
    "    # save file\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_stations = prices_data09.station_uuid.unique()\n",
    "# active_stations_sample = np.random.choice(active_stations, size=100)\n",
    "# pds = prices_df.query('station_uuid in @active_stations_sample')\n",
    "# pds\n",
    "\n",
    "\n",
    "\n",
    "# create a table that carries all stations for each hour of the day\n",
    "\n",
    "# group by the hour of the day, take the average price if a station is occuring more than once during that time\n",
    "\n",
    "# if a station occurs, check the *change columns if its a 2 or a 3, and if yes, check if the price is actually different from the previous hour of if prices have just been re-reported\n",
    "\n",
    "# if prices changed then make a 1 in the price-changed-dummies\n",
    "\n",
    "# if there are multiple occurences of the same station within one hour, check which prices changed and make en entry for the respective dummy\n",
    "\n",
    "# if there are multiple occurences of the same station within one hour, for each of the 3 fuel prices, count how often it changed\n",
    "\n",
    "# take a batch for each hour of the day\n",
    "\n",
    "# check \n",
    "\n",
    "# df = pd.merge(df, pds, how='left', on=['date', 'station_uuid']).set_index(['date', 'station_uuid'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuel_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
